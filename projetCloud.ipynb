{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498ac73b",
   "metadata": {
    "gather": {
     "logged": 1646790705849
    }
   },
   "outputs": [],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ab13b6",
   "metadata": {
    "gather": {
     "logged": 1646790706418
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.38.0 to work with projetcloud\n"
     ]
    }
   ],
   "source": [
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b5367e",
   "metadata": {
    "gather": {
     "logged": 1646790723027
    }
   },
   "outputs": [],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "df = ws.datasets[\"sample\"]\n",
    "\n",
    "# Display the first 20 rows as a Pandas dataframe\n",
    "df = df.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "293be9a1",
   "metadata": {
    "gather": {
     "logged": 1646790723134
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files folder created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'files'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "208e0c84",
   "metadata": {
    "gather": {
     "logged": 1646790723401
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"myCC1606\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4ceb982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting files/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/preprocessing.py\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "from azureml.core import Run, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
    "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
    "args = parser.parse_args()\n",
    "save_folder = args.prepped_data\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Get the training dataset\n",
    "print(\"Loading Data...\")\n",
    "df = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
    "\n",
    "run.log('raw_df_len', len(df))\n",
    "\n",
    "# remove some useless columns\n",
    "df.date_mutation=pd.to_datetime(df.date_mutation)\n",
    "to_drop = [\"id_mutation\",\"numero_disposition\",\"adresse_numero\",\"adresse_nom_voie\",\"adresse_code_voie\",\"code_postal\",\n",
    "           \"adresse_suffixe\",\"code_commune\",\"nom_commune\",\"code_departement\",\"ancien_code_commune\", \"ancien_nom_commune\",\n",
    "           \"id_parcelle\",\"ancien_id_parcelle\",\"type_local\",\"nature_culture\",\"nature_culture_speciale\",\"code_nature_culture_speciale\",\n",
    "          \"lot1_numero\",\"lot2_numero\",\"lot3_numero\",\"lot4_numero\",\"lot5_numero\", \"numero_volume\", \"lot3_surface_carrez\", \"lot4_surface_carrez\",\n",
    "          \"lot5_surface_carrez\"]\n",
    "\n",
    "reduced_df = df.drop(to_drop, axis=1)\n",
    "\n",
    "# get_dummies\n",
    "reduced_df = pd.get_dummies(reduced_df, columns=[\"code_nature_culture\", \"nature_mutation\"])\n",
    "\n",
    "# feature engineering\n",
    "reduced_df[\"year_mutation\"] = reduced_df.date_mutation.dt.year\n",
    "reduced_df[\"code_type_local\"] = 5-reduced_df.code_type_local\n",
    "\n",
    "reduced_df = reduced_df.drop(\"date_mutation\",axis=1)\n",
    "\n",
    "# manage missing values\n",
    "final_df = reduced_df.fillna(reduced_df.mean())\n",
    "\n",
    "\n",
    "# Log raw row count\n",
    "row_count = (len(final_df))\n",
    "run.log('processed_rows', row_count)\n",
    "\n",
    "# Normalization\n",
    "X = final_df.drop(\"valeur_fonciere\", axis=1)\n",
    "cols = X.columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "final_df[cols] = scaler.fit_transform(X)\n",
    "\n",
    "run.log('number of parameters', len(final_df))\n",
    "run.log('scaler range len', len(scaler.data_range_))\n",
    "run.log_list('params',list(final_df.columns.values))\n",
    "\n",
    "# Save the prepped data\n",
    "print(\"Saving Data...\")\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_path = os.path.join(save_folder,'data.csv')\n",
    "final_df.to_csv(save_path, index=False, header=True)\n",
    "\n",
    "joblib.dump(value=scaler, filename='outputs/myscaler.scl')\n",
    "joblib.dump(value=final_df.columns, filename='outputs/cols.cl')\n",
    "\n",
    "# End the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b37de3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting files/training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/training.py\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "from azureml.core import Run, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Get the script arguments (regularization rate and training dataset ID)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training dataset')\n",
    "parser.add_argument(\"--age\", type=str, dest='age', help='age')\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "training_data = args.training_data\n",
    "\n",
    "# load the prepared data file in the training folder\n",
    "print(\"Loading Data...\")\n",
    "file_path = os.path.join(training_data,'data.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "run.log('final prep dataset len', len(df))\n",
    "run.log('cols', len(df.columns))\n",
    "\n",
    "# Separate features and labels\n",
    "y = df.valeur_fonciere\n",
    "\n",
    "X = df.drop(\"valeur_fonciere\",axis=1)\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# calculate metrics\n",
    "print('train score:', model.score(X_train, y_train))\n",
    "print('test score:' , model.score(X_test, y_test))\n",
    "\n",
    "run.log('train_score', model.score(X_train, y_train))\n",
    "run.log('test_score', model.score(X_test, y_test))\n",
    "\n",
    "run.log('number of parameters', len(model.coef_))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/projetCloud_model.pkl')\n",
    "\n",
    "\n",
    "print('Model trained and registered.')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10e90aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting files/experiment_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/experiment_env.yml\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fad4ebd5-8a67-4bd8-92e5-2c387a0ca01e",
   "metadata": {
    "gather": {
     "logged": 1646790723615
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\n",
    "\n",
    "# Register the environment \n",
    "experiment_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'experiment_env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5961adbe-0fed-481e-bacd-7c308b8d6cfc",
   "metadata": {
    "gather": {
     "logged": 1646790723832
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# Get the training dataset\n",
    "#ds = ws.datasets.get(\"Rhone Alpes Dataset\")\n",
    "ds = ws.datasets.get(\"sample\")\n",
    "\n",
    "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
    "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\n",
    "\n",
    "# Step 1, Run the data prep script\n",
    "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"preprocessing.py\",\n",
    "                                arguments = ['--input-data', ds.as_named_input('raw_data'),\n",
    "                                             '--prepped-data', prepped_data],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "# Step 2, run the training script\n",
    "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"training.py\",\n",
    "                                arguments = ['--training-data', prepped_data.as_input(), \n",
    "                                            '--age', 14],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c9d3bc9-ce5f-431a-8511-37fa0a283adf",
   "metadata": {
    "gather": {
     "logged": 1646791369706
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Prepare Data [53517816][a02a3c73-39cf-43d9-8042-130c4d69743e], (This step will run and generate new outputs)\n",
      "Created step Train and Register Model [918f5e93][71e2ba3f-07bc-44d3-9b7b-15f2403b51fd], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 9bf9e0a6-9a37-4b87-8352-d0ddf8409fb5\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9bf9e0a6-9a37-4b87-8352-d0ddf8409fb5?wsid=/subscriptions/686d0f0b-ae0f-4e57-a751-af55cb836ef2/resourcegroups/projetcloud/workspaces/projetcloud&tid=190ce420-b157-44ae-bc2f-69563baa5a3b\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5be49118dd4eb7b926a75268e5a3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"loading\": true}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 9bf9e0a6-9a37-4b87-8352-d0ddf8409fb5\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9bf9e0a6-9a37-4b87-8352-d0ddf8409fb5?wsid=/subscriptions/686d0f0b-ae0f-4e57-a751-af55cb836ef2/resourcegroups/projetcloud/workspaces/projetcloud&tid=190ce420-b157-44ae-bc2f-69563baa5a3b\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: feab8e51-92e3-4bc2-9596-5ed19347af05\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/feab8e51-92e3-4bc2-9596-5ed19347af05?wsid=/subscriptions/686d0f0b-ae0f-4e57-a751-af55cb836ef2/resourcegroups/projetcloud/workspaces/projetcloud&tid=190ce420-b157-44ae-bc2f-69563baa5a3b\n",
      "StepRun( Prepare Data ) Status: NotStarted\n",
      "StepRun( Prepare Data ) Status: Running\n",
      "\n",
      "StepRun(Prepare Data) Execution Summary\n",
      "========================================\n",
      "StepRun( Prepare Data ) Status: Finished\n"
     ]
    },
    {
     "ename": "ExperimentExecutionException",
     "evalue": "ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:737\u001b[0m, in \u001b[0;36mStepRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_run_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:832\u001b[0m, in \u001b[0;36mStepRun._stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ActivityFailedException(error_details\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m--> 832\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_details\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_loggerfactory.py:132\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/abstract_dataset.py:764\u001b[0m, in \u001b[0;36mAbstractDataset.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dataprep_installed():\n\u001b[0;32m--> 764\u001b[0m     steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataflow\u001b[49m\u001b[38;5;241m.\u001b[39m_get_steps()\n\u001b[1;32m    765\u001b[0m     step_type \u001b[38;5;241m=\u001b[39m steps[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstep_type\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_loggerfactory.py:132\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/abstract_dataset.py:217\u001b[0m, in \u001b[0;36mAbstractDataset._dataflow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registration \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registration\u001b[38;5;241m.\u001b[39mworkspace:\n\u001b[0;32m--> 217\u001b[0m     \u001b[43mdataprep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datastore_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_auth_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_registration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkspace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_definition, dataprep()\u001b[38;5;241m.\u001b[39mDataflow):\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_datastore_helper.py:185\u001b[0m, in \u001b[0;36m_set_auth_type\u001b[0;34m(workspace)\u001b[0m\n\u001b[1;32m    184\u001b[0m auth_value \u001b[38;5;241m=\u001b[39m auth\n\u001b[0;32m--> 185\u001b[0m \u001b[43mget_engine_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_aml_auth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSetAmlAuthMessageArgument\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth_value\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_aml_helper.py:38\u001b[0m, in \u001b[0;36mupdate_aml_env_vars.<locals>.decorator.<locals>.wrapper\u001b[0;34m(op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m     37\u001b[0m     engine_api_func()\u001b[38;5;241m.\u001b[39mupdate_environment_variable(changed)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msend_message_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_token\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/api.py:290\u001b[0m, in \u001b[0;36mEngineAPI.set_aml_auth\u001b[0;34m(self, message_args, cancellation_token)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;129m@update_aml_env_vars\u001b[39m(get_engine_api)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_aml_auth\u001b[39m(\u001b[38;5;28mself\u001b[39m, message_args: typedefinitions\u001b[38;5;241m.\u001b[39mSetAmlAuthMessageArgument, cancellation_token: CancellationToken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_message_channel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEngine.SetAmlAuth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/engine.py:247\u001b[0m, in \u001b[0;36mMultiThreadMessageChannel.send_message\u001b[0;34m(self, op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_was_relaunched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_relaunch_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_message_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/api.py:105\u001b[0m, in \u001b[0;36mEngineAPI.__init__.<locals>.connect_to_requests_channel\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect_to_requests_channel\u001b[39m():\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine_server_secret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_host_secret\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequests_channel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost_secret\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine_server_port \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync_host_channel_port(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequests_channel\u001b[38;5;241m.\u001b[39mport)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_aml_helper.py:38\u001b[0m, in \u001b[0;36mupdate_aml_env_vars.<locals>.decorator.<locals>.wrapper\u001b[0;34m(op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m     37\u001b[0m     engine_api_func()\u001b[38;5;241m.\u001b[39mupdate_environment_variable(changed)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msend_message_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_token\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/api.py:305\u001b[0m, in \u001b[0;36mEngineAPI.sync_host_secret\u001b[0;34m(self, message_args, cancellation_token)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;129m@update_aml_env_vars\u001b[39m(get_engine_api)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msync_host_secret\u001b[39m(\u001b[38;5;28mself\u001b[39m, message_args: \u001b[38;5;28mstr\u001b[39m, cancellation_token: CancellationToken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m--> 305\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_message_channel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEngine.SyncHostSecret\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/engine.py:271\u001b[0m, in \u001b[0;36mMultiThreadMessageChannel.send_message\u001b[0;34m(self, op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_line(json\u001b[38;5;241m.\u001b[39mdumps({\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessageId\u001b[39m\u001b[38;5;124m'\u001b[39m: message_id,\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopCode\u001b[39m\u001b[38;5;124m'\u001b[39m: op_code,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: message\n\u001b[1;32m    269\u001b[0m }, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39mCustomEncoder))\n\u001b[0;32m--> 271\u001b[0m \u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_messages_lock:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mExperimentExecutionException\u001b[0m              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline submitted for execution.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m RunDetails(pipeline_run)\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mpipeline_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:295\u001b[0m, in \u001b[0;36mPipelineRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[43mstep_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime_elapsed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# If there are package conflicts in the user's environment, the run rehydration\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# will not work and we will receive a Run object instead of StepRun.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# Run.wait_for_completion() does not have a parameter timeout_seconds, which\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# will generate a TypeError here.  As a workaround, call the method without\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# this parameter.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step_run, StepRun):\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:745\u001b[0m, in \u001b[0;36mStepRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    740\u001b[0m         error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output streaming for the run interrupted.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    741\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBut the run is still executing on the compute target. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    742\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails for canceling the run can be found here: \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    743\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://aka.ms/aml-docs-cancel-run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 745\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExperimentExecutionException(error_message)\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_status()\n",
      "\u001b[0;31mExperimentExecutionException\u001b[0m: ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps =  [prep_step, train_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace=ws, name = 'projetCloud-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe81c14",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c791cfd6-8a59-4502-8bc4-5e743324d18e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'final prep dataset len': 10000, 'cols': 42, 'train_score': 0.03865846433414477, 'test_score': 0.029905695717371894, 'number of parameters': 41}\n",
      "{'raw_df_len': 10000, 'processed_rows': 10000, 'number of parameters': 10000, 'scaler range len': 41, 'params': ['valeur_fonciere', 'lot1_surface_carrez', 'lot2_surface_carrez', 'nombre_lots', 'code_type_local', 'surface_reelle_bati', 'nombre_pieces_principales', 'surface_terrain', 'longitude', 'latitude', 'code_nature_culture_AB', 'code_nature_culture_AG', 'code_nature_culture_B', 'code_nature_culture_BF', 'code_nature_culture_BM', 'code_nature_culture_BP', 'code_nature_culture_BR', 'code_nature_culture_BS', 'code_nature_culture_BT', 'code_nature_culture_CA', 'code_nature_culture_CH', 'code_nature_culture_E', 'code_nature_culture_J', 'code_nature_culture_L', 'code_nature_culture_LB', 'code_nature_culture_P', 'code_nature_culture_PA', 'code_nature_culture_PC', 'code_nature_culture_PE', 'code_nature_culture_PH', 'code_nature_culture_PP', 'code_nature_culture_S', 'code_nature_culture_T', 'code_nature_culture_VE', 'code_nature_culture_VI', 'nature_mutation_Adjudication', 'nature_mutation_Echange', 'nature_mutation_Expropriation', 'nature_mutation_Vente', \"nature_mutation_Vente en l'état futur d'achèvement\", 'nature_mutation_Vente terrain à bâtir', 'year_mutation']}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for run in pipeline_run.get_children():\n",
    "    print(run.get_metrics())\n",
    "    if i==1:\n",
    "        run.register_model(model_path='outputs/myscaler.scl', model_name='projetCloud_scaler')\n",
    "        run.register_model(model_path='outputs/cols.cl', model_name='projetCloud_df_cols')\n",
    "    else:\n",
    "        run.register_model(model_path='outputs/projetCloud_model.pkl', model_name='projetCloud_model',\n",
    "        properties = {'train_score': run.get_metrics()['train_score'], 'test_score': run.get_metrics()['test_score']})\n",
    "    i=1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e9bd37-0632-4a50-a06d-27d82d328c64",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "953c2cb2-90a0-4a3f-a492-4206f51ee059",
   "metadata": {
    "gather": {
     "logged": 1646792711769
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projetCloud_model version 2\n",
      "./service folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azureml.core import Model\n",
    " \n",
    "\n",
    "model = ws.models['projetCloud_model']\n",
    "scaler = ws.models['projetCloud_scaler']\n",
    "df_columns = ws.models['projetCloud_df_cols']\n",
    "\n",
    "print(model.name, 'version', model.version)\n",
    "\n",
    "# Create a folder for the deployment files\n",
    "deployment_folder = './service'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "print(deployment_folder, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = 'projetCloud_api.py'\n",
    "script_path = os.path.join(deployment_folder,script_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2bc3f74-22d0-417b-bf4a-71bcfda5ad81",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./service/projetCloud_api.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    global scaler\n",
    "    \n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'),'projetCloud_model','2','projetCloud_model.pkl')\n",
    "    scaler_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'),'projetCloud_scaler','2','myscaler.scl')\n",
    "    \n",
    "    model = joblib.load(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    \n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    print(scaler.transform(data))\n",
    "    print(model.coef_)\n",
    "    print(model.intercept_)\n",
    "    predictions = model.predict(scaler.transform(data))\n",
    "    print(f\"price: {predictions[0]}\")\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps({\"result\": float(predictions[0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b7e51fb-b97d-40c7-84cd-821b0bbd02ec",
   "metadata": {
    "gather": {
     "logged": 1646793174011
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model...\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-03-31 00:07:57+00:00 Creating Container Registry if not exists.\n",
      "2022-03-31 00:07:57+00:00 Registering the environment.\n",
      "2022-03-31 00:07:58+00:00 Use the existing image.\n",
      "2022-03-31 00:07:58+00:00 Generating deployment configuration.\n",
      "2022-03-31 00:08:00+00:00 Submitting deployment to compute.\n",
      "2022-03-31 00:08:02+00:00 Checking the status of deployment projetcloud-service..\n",
      "2022-03-31 00:10:14+00:00 Checking the status of inference endpoint projetcloud-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "# Configure the scoring environment\n",
    "service_env = Environment(name='service-env')\n",
    "python_packages = ['scikit-learn', 'azureml-defaults', 'azure-ml-api-sdk']\n",
    "for package in python_packages:\n",
    "    service_env.python.conda_dependencies.add_pip_package(package)\n",
    "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
    "                                   entry_script=script_file,\n",
    "                                   environment=service_env)\n",
    "\n",
    "# Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print('Deploying model...')\n",
    "service_name = \"projetcloud-service\"\n",
    "service = Model.deploy(ws, service_name, [model,scaler], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd317c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
