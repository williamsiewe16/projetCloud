{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import azureml\n",
        "from azureml.core import Workspace\n",
        "from azureml.core import Dataset"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1646790705849
        }
      },
      "id": "498ac73b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.38.0 to work with projetcloud\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1646790706418
        }
      },
      "id": "64ab13b6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the default datastore\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "df = ws.datasets[\"sample\"]\n",
        "\n",
        "# Display the first 20 rows as a Pandas dataframe\n",
        "df = df.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1646790723027
        }
      },
      "id": "63b5367e"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "experiment_folder = 'files'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "files folder created\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1646790723134
        }
      },
      "id": "293be9a1"
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"myCC1606\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1646790723401
        }
      },
      "id": "208e0c84"
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\n",
        "\n",
        "# Register the environment \n",
        "experiment_env.register(workspace=ws)\n",
        "registered_env = Environment.get(ws, 'experiment_env')\n",
        "\n",
        "# Create a new runconfig object for the pipeline\n",
        "pipeline_run_config = RunConfiguration()\n",
        "\n",
        "# Use the compute you created above. \n",
        "pipeline_run_config.target = pipeline_cluster\n",
        "\n",
        "# Assign the environment to the run configuration\n",
        "pipeline_run_config.environment = registered_env\n",
        "\n",
        "print (\"Run configuration created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run configuration created.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1646790723615
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "fad4ebd5-8a67-4bd8-92e5-2c387a0ca01e"
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "\n",
        "# Get the training dataset\n",
        "#ds = ws.datasets.get(\"Rhone Alpes Dataset\")\n",
        "ds = ws.datasets.get(\"sample\")\n",
        "\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
        "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\n",
        "\n",
        "# Step 1, Run the data prep script\n",
        "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"preprocessing.py\",\n",
        "                                arguments = ['--input-data', ds.as_named_input('raw_data'),\n",
        "                                             '--prepped-data', prepped_data],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "# Step 2, run the training script\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"training.py\",\n",
        "                                arguments = ['--training-data', prepped_data.as_input(), \n",
        "                                            '--age', 14],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline steps defined\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1646790723832
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "5961adbe-0fed-481e-bacd-7c308b8d6cfc"
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Construct the pipeline\n",
        "pipeline_steps =  [prep_step, train_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
        "print(\"Pipeline is built.\")\n",
        "\n",
        "# Create an experiment and run the pipeline\n",
        "experiment = Experiment(workspace=ws, name = 'projetCloud-pipeline')\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
        "print(\"Pipeline submitted for execution.\")\n",
        "RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline is built.\nCreated step Prepare Data [1404e102][96fe04e3-74f1-427a-8476-1148a3c89aca], (This step will run and generate new outputs)\nCreated step Train and Register Model [311e7532][685573ab-ac2b-4e29-bdc1-38f0685a082d], (This step will run and generate new outputs)\nSubmitted PipelineRun dd98fe87-29bd-40da-a3df-b87c06c9b383\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/dd98fe87-29bd-40da-a3df-b87c06c9b383?wsid=/subscriptions/686d0f0b-ae0f-4e57-a751-af55cb836ef2/resourcegroups/projetcloud/workspaces/projetcloud&tid=190ce420-b157-44ae-bc2f-69563baa5a3b\nPipeline submitted for execution.\nPipelineRunId: dd98fe87-29bd-40da-a3df-b87c06c9b383\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/dd98fe87-29bd-40da-a3df-b87c06c9b383?wsid=/subscriptions/686d0f0b-ae0f-4e57-a751-af55cb836ef2/resourcegroups/projetcloud/workspaces/projetcloud&tid=190ce420-b157-44ae-bc2f-69563baa5a3b\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a7c17cbec264abcb493165d09c49e1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/dd98fe87-29bd-40da-a3df-b87c06c9b383?wsid=/subscriptions/686d0f0b-ae0f-4e57-a751-af55cb836ef2/resourcegroups/projetcloud/workspaces/projetcloud&tid=190ce420-b157-44ae-bc2f-69563baa5a3b\", \"run_id\": \"dd98fe87-29bd-40da-a3df-b87c06c9b383\", \"run_properties\": {\"run_id\": \"dd98fe87-29bd-40da-a3df-b87c06c9b383\", \"created_utc\": \"2022-03-09T01:52:21.313371Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": \"2022-03-09T02:02:47.196377Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.dd98fe87-29bd-40da-a3df-b87c06c9b383/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=K0WoZgU3tmxbkYKNTnyS3ecKpiuR1DYDB03qxEWjAeo%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T02%3A13%3A40Z&se=2022-03-09T10%3A23%3A40Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.dd98fe87-29bd-40da-a3df-b87c06c9b383/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=j%2FVWmqhYU9ZwZ%2B2FxPJpcDl22s%2Fnxq9c0zPoZPkcCa0%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T02%3A13%3A40Z&se=2022-03-09T10%3A23%3A40Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.dd98fe87-29bd-40da-a3df-b87c06c9b383/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=pgTKloth8Opt0nxczFQaCpr3UhYr4mwrdQxioXAUuAA%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T02%3A13%3A40Z&se=2022-03-09T10%3A23%3A40Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:10:25\", \"run_number\": \"1646790741\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2022-03-09T02:00:26.0632Z\", \"created_time\": \"2022-03-09T01:52:23.591178Z\", \"end_time\": \"2022-03-09T02:02:15.841495Z\", \"duration\": \"0:09:52\", \"run_number\": 1646790743, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-03-09T01:52:23.591178Z\", \"is_reused\": \"\"}, {\"run_id\": \"0cd3a2a9-a611-4d36-a4a7-ce7c7cc57994\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2022-03-09T02:02:25.618419Z\", \"created_time\": \"2022-03-09T02:02:18.551893Z\", \"end_time\": \"2022-03-09T02:02:44.53013Z\", \"duration\": \"0:00:25\", \"run_number\": 1646791338, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-03-09T02:02:18.551893Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-03-09 01:52:23Z] Submitting 1 runs, first five are: 1404e102:0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a\\n[2022-03-09 02:02:18Z] Completing processing run id 0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a.\\n[2022-03-09 02:02:18Z] Submitting 1 runs, first five are: 311e7532:0cd3a2a9-a611-4d36-a4a7-ce7c7cc57994\\n[2022-03-09 02:02:46Z] Completing processing run id 0cd3a2a9-a611-4d36-a4a7-ce7c7cc57994.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"5fcf4f95\": {\"node_id\": \"5fcf4f95\", \"name\": \"sample\"}}, \"module_nodes\": {\"1404e102\": {\"node_id\": \"1404e102\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a\"}, \"311e7532\": {\"node_id\": \"311e7532\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"0cd3a2a9-a611-4d36-a4a7-ce7c7cc57994\"}}, \"edges\": [{\"source_node_id\": \"5fcf4f95\", \"source_node_name\": \"sample\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"1404e102\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"1404e102\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data\", \"target_name\": \"input_27290d83\", \"dst_node_id\": \"311e7532\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2022-03-09T02:00:26.0632Z\", \"created_time\": \"2022-03-09T01:52:23.591178Z\", \"end_time\": \"2022-03-09T02:02:15.841495Z\", \"duration\": \"0:09:52\", \"run_number\": 1646790743, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-03-09T01:52:23.591178Z\", \"is_reused\": \"\"}, {\"run_id\": \"0cd3a2a9-a611-4d36-a4a7-ce7c7cc57994\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2022-03-09T02:02:25.618419Z\", \"created_time\": \"2022-03-09T02:02:18.551893Z\", \"end_time\": \"2022-03-09T02:02:44.53013Z\", \"duration\": \"0:00:25\", \"run_number\": 1646791338, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-03-09T02:02:18.551893Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.38.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRun Status: Running\n\n\nStepRunId: 0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a?wsid=/subscriptions/686d0f0b-ae0f-4e57-a751-af55cb836ef2/resourcegroups/projetcloud/workspaces/projetcloud&tid=190ce420-b157-44ae-bc2f-69563baa5a3b\nStepRun( Prepare Data ) Status: Running\n\nStepRun(Prepare Data) Execution Summary\n========================================\nStepRun( Prepare Data ) Status: Finished\n{'runId': '0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a', 'target': 'myCC1606', 'status': 'Completed', 'startTimeUtc': '2022-03-09T02:00:26.0632Z', 'endTimeUtc': '2022-03-09T02:02:15.841495Z', 'services': {}, 'properties': {'ContentSnapshotId': 'db3a1d7e-f161-45d4-877f-9ecf318275e6', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '96fe04e3-74f1-427a-8476-1148a3c89aca', 'azureml.moduleName': 'Prepare Data', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '1404e102', 'azureml.pipelinerunid': 'dd98fe87-29bd-40da-a3df-b87c06c9b383', 'azureml.pipeline': 'dd98fe87-29bd-40da-a3df-b87c06c9b383', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'e04cca93-36d8-4998-9bac-0f051bc93e47'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': '99aaaa6a-03a8-4710-bfee-2fa9b3ab7815'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'prepped_data'}, 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'dataset/0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a/prepped_data/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"99aaaa6a-03a8-4710-bfee-2fa9b3ab7815\",\n    \"name\": null,\n    \"version\": null,\n    \"workspace\": \"Workspace.create(name='projetcloud', subscription_id='686d0f0b-ae0f-4e57-a751-af55cb836ef2', resource_group='projetcloud')\"\n  }\n}}], 'runDefinition': {'script': 'preprocessing.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', 'DatasetOutputConfig:prepped_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'myCC1606', 'dataReferences': {}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': 'e04cca93-36d8-4998-9bac-0f051bc93e47', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'prepped_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': 'dd98fe87-29bd-40da-a3df-b87c06c9b383', 'azureml.pipelineRun.moduleNodeId': '1404e102', 'azureml.pipelineRun.outputPortName': 'prepped_data'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '1', 'assetId': 'azureml://locations/westeurope/workspaces/6a9ab5d0-33da-4dbe-9863-5c715c873107/environments/experiment_env/versions/1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/backgroundProcess.log': 'https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=HcSqn9McHpn6jKXwJQVdY5sZRnsj%2BKf4ecCso%2BYQCg4%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T01%3A52%3A12Z&se=2022-03-09T10%3A02%3A12Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=6tcdib46bULfZbvjpvKIVu%2Bu2O%2B47Z44NQoHS4Vp%2FNM%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T01%3A52%3A12Z&se=2022-03-09T10%3A02%3A12Z&sp=r', 'logs/azureml/dataprep/rslex.log': 'https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a/logs/azureml/dataprep/rslex.log?sv=2019-07-07&sr=b&sig=FS0XPTsZWAbqwFBmEJc1Di0v%2BspoEOYcTON%2BuFkHb%2Bo%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T01%3A52%3A12Z&se=2022-03-09T10%3A02%3A12Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=uA%2BGmXWyw2TrYazgPBLGbepeYudy9eEVu%2F%2FE40iRdcg%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T01%3A52%3A12Z&se=2022-03-09T10%3A02%3A12Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=eUnKvY4AiFb3v92vC29ow3IsfrHsaC8h83dHh8SgZUk%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T01%3A52%3A12Z&se=2022-03-09T10%3A02%3A12Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.0e69d4da-8caa-4a29-b2db-bfbcc95a5f9a/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=XCtXVypViGMG7%2BNP8lsmXltG6Y33Mc0TMy%2FYAjyEtKY%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T01%3A52%3A12Z&se=2022-03-09T10%3A02%3A12Z&sp=r'}, 'submittedBy': 'Loic SIEWE'}\n\n\n\n\nStepRunId: 0cd3a2a9-a611-4d36-a4a7-ce7c7cc57994\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/0cd3a2a9-a611-4d36-a4a7-ce7c7cc57994?wsid=/subscriptions/686d0f0b-ae0f-4e57-a751-af55cb836ef2/resourcegroups/projetcloud/workspaces/projetcloud&tid=190ce420-b157-44ae-bc2f-69563baa5a3b\nStepRun( Train and Register Model ) Status: Running\n\nStepRun(Train and Register Model) Execution Summary\n====================================================\nStepRun( Train and Register Model ) Status: Finished\n{'runId': '0cd3a2a9-a611-4d36-a4a7-ce7c7cc57994', 'target': 'myCC1606', 'status': 'Completed', 'startTimeUtc': '2022-03-09T02:02:25.618419Z', 'endTimeUtc': '2022-03-09T02:02:44.53013Z', 'services': {}, 'properties': {'ContentSnapshotId': 'db3a1d7e-f161-45d4-877f-9ecf318275e6', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '685573ab-ac2b-4e29-bdc1-38f0685a082d', 'azureml.moduleName': 'Train and Register Model', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '311e7532', 'azureml.pipelinerunid': 'dd98fe87-29bd-40da-a3df-b87c06c9b383', 'azureml.pipeline': 'dd98fe87-29bd-40da-a3df-b87c06c9b383', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '99aaaa6a-03a8-4710-bfee-2fa9b3ab7815'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input_27290d83', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'training.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--training-data', 'DatasetConsumptionConfig:input_27290d83', '--age', '14'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'myCC1606', 'dataReferences': {}, 'data': {'input_27290d83': {'dataLocation': {'dataset': {'id': '99aaaa6a-03a8-4710-bfee-2fa9b3ab7815', 'name': None, 'version': None}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'environmentVariableName': 'input_27290d83', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '1', 'assetId': 'azureml://locations/westeurope/workspaces/6a9ab5d0-33da-4dbe-9863-5c715c873107/environments/experiment_env/versions/1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.0cd3a2a9-a611-4d36-a4a7-ce7c7cc57994/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=8nCxC1ULJ95PjHekEfhkawxip4uzuCTT0zaNtDmDQG0%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T01%3A52%3A24Z&se=2022-03-09T10%3A02%3A24Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.0cd3a2a9-a611-4d36-a4a7-ce7c7cc57994/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=UvaVnGVEmXdQdUwxBqXiHZOxStvw0wkc2dYy%2BMfU1Yw%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T01%3A52%3A24Z&se=2022-03-09T10%3A02%3A24Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.0cd3a2a9-a611-4d36-a4a7-ce7c7cc57994/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=C5oEeV5Cf9qY3cVGAIcyc2l07VQnr9LhcqZrlWfW88E%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T01%3A52%3A24Z&se=2022-03-09T10%3A02%3A24Z&sp=r'}, 'submittedBy': 'Loic SIEWE'}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': 'dd98fe87-29bd-40da-a3df-b87c06c9b383', 'status': 'Completed', 'startTimeUtc': '2022-03-09T01:52:22.548506Z', 'endTimeUtc': '2022-03-09T02:02:47.196377Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.dd98fe87-29bd-40da-a3df-b87c06c9b383/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=Ijc8w0fqh5AqNPj09SfcOMQa8irF5OfPtTi2lmPXphk%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T01%3A52%3A49Z&se=2022-03-09T10%3A02%3A49Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.dd98fe87-29bd-40da-a3df-b87c06c9b383/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=IwsGyQiCn2lnSwDplIOd7U2GX6tjwey8Nc2FUilKrN8%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T01%3A52%3A49Z&se=2022-03-09T10%3A02%3A49Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://projetcloud2405615726.blob.core.windows.net/azureml/ExperimentRun/dcid.dd98fe87-29bd-40da-a3df-b87c06c9b383/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=n0lbSTDIf480YiX7VFXwFMkQR4yKoj%2FIYpt8g3Et9v4%3D&skoid=87e06d1f-c863-4ad5-bf6e-242a2e5f0b6d&sktid=190ce420-b157-44ae-bc2f-69563baa5a3b&skt=2022-03-08T18%3A33%3A03Z&ske=2022-03-10T02%3A43%3A03Z&sks=b&skv=2019-07-07&st=2022-03-09T01%3A52%3A49Z&se=2022-03-09T10%3A02%3A49Z&sp=r'}, 'submittedBy': 'Loic SIEWE'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1646791369706
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "1c9d3bc9-ce5f-431a-8511-37fa0a283adf"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/preprocessing.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "from azureml.core import Run, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
        "args = parser.parse_args()\n",
        "save_folder = args.prepped_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Get the training dataset\n",
        "print(\"Loading Data...\")\n",
        "df = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
        "\n",
        "run.log('raw_df_len', len(df))\n",
        "\n",
        "# remove some useless columns\n",
        "df.date_mutation=pd.to_datetime(df.date_mutation)\n",
        "to_drop = [\"id_mutation\",\"numero_disposition\",\"adresse_numero\",\"adresse_nom_voie\",\"adresse_code_voie\",\"code_postal\",\n",
        "           \"adresse_suffixe\",\"code_commune\",\"nom_commune\",\"code_departement\",\"ancien_code_commune\", \"ancien_nom_commune\",\n",
        "           \"id_parcelle\",\"ancien_id_parcelle\",\"type_local\",\"nature_culture\",\"nature_culture_speciale\",\"code_nature_culture_speciale\",\n",
        "          \"lot1_numero\",\"lot2_numero\",\"lot3_numero\",\"lot4_numero\",\"lot5_numero\", \"numero_volume\", \"lot3_surface_carrez\", \"lot4_surface_carrez\",\n",
        "          \"lot5_surface_carrez\"]\n",
        "\n",
        "reduced_df = df.drop(to_drop, axis=1)\n",
        "\n",
        "# get_dummies\n",
        "reduced_df = pd.get_dummies(reduced_df, columns=[\"code_nature_culture\", \"nature_mutation\"])\n",
        "\n",
        "# feature engineering\n",
        "reduced_df[\"year_mutation\"] = reduced_df.date_mutation.dt.year\n",
        "reduced_df[\"code_type_local\"] = 5-reduced_df.code_type_local\n",
        "\n",
        "reduced_df = reduced_df.drop(\"date_mutation\",axis=1)\n",
        "\n",
        "# manage missing values\n",
        "final_df = reduced_df.fillna(reduced_df.mean())\n",
        "\n",
        "\n",
        "# Log raw row count\n",
        "row_count = (len(final_df))\n",
        "run.log('processed_rows', row_count)\n",
        "\n",
        "# Normalization\n",
        "X = final_df.drop(\"valeur_fonciere\", axis=1)\n",
        "cols = X.columns\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "final_df[cols] = scaler.fit_transform(X)\n",
        "\n",
        "run.log_list('nulls', list((final_df.isna()).sum(axis=0).values))\n",
        "\n",
        "# Save the prepped data\n",
        "print(\"Saving Data...\")\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "save_path = os.path.join(save_folder,'data.csv')\n",
        "final_df.to_csv(save_path, index=False, header=True)\n",
        "\n",
        "joblib.dump(value=scaler, filename='outputs/myscaler.scl')\n",
        "joblib.dump(value=final_df.columns, filename='outputs/cols.cl')\n",
        "\n",
        "# End the run\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting files/preprocessing.py\n"
        }
      ],
      "execution_count": 8,
      "metadata": {},
      "id": "e4ceb982"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "0a3022ef-9f49-4a16-9e96-8ceea6b34594"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/training.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "from azureml.core import Run, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "# Get the script arguments (regularization rate and training dataset ID)\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training dataset')\n",
        "parser.add_argument(\"--age\", type=str, dest='age', help='age')\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "training_data = args.training_data\n",
        "\n",
        "# load the prepared data file in the training folder\n",
        "print(\"Loading Data...\")\n",
        "file_path = os.path.join(training_data,'data.csv')\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "run.log('final prep dataset len', len(df))\n",
        "run.log('cols', len(df.columns))\n",
        "\n",
        "# Separate features and labels\n",
        "y = df.valeur_fonciere\n",
        "\n",
        "run.log(\"nb null values\", (df.isna()).sum(axis=0).sum())\n",
        "X = df.drop(\"valeur_fonciere\",axis=1)\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# calculate metrics\n",
        "print('train score:', model.score(X_train, y_train))\n",
        "print('test score:' , model.score(X_test, y_test))\n",
        "\n",
        "run.log('train_score', model.score(X_train, y_train))\n",
        "run.log('test_score', model.score(X_test, y_test))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
        "joblib.dump(value=model, filename='outputs/projetCloud_model.pkl')\n",
        "\n",
        "\n",
        "print('Model trained and registered.')\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting files/training.py\n"
        }
      ],
      "execution_count": 9,
      "metadata": {},
      "id": "b37de3aa"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/experiment_env.yml\n",
        "name: experiment_env\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- ipykernel\n",
        "- matplotlib\n",
        "- pandas\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - pyarrow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting files/experiment_env.yml\n"
        }
      ],
      "execution_count": 11,
      "metadata": {},
      "id": "10e90aae"
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\r\n",
        "for run in pipeline_run.get_children():\r\n",
        "    print(run.get_metrics())\r\n",
        "    if i==1:\r\n",
        "        run.register_model(model_path='outputs/myscaler.scl', model_name='projetCloud_scaler')\r\n",
        "        run.register_model(model_path='outputs/cols.cl', model_name='projetCloud_df_cols')\r\n",
        "    else:\r\n",
        "        run.register_model(model_path='outputs/projetCloud_model.pkl', model_name='projetCloud_model',\r\n",
        "        properties = {'train_score': run.get_metrics()['train_score'], 'test_score': run.get_metrics()['test_score']})\r\n",
        "    i=1  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "c791cfd6-8a59-4502-8bc4-5e743324d18e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Deployment**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "39e9bd37-0632-4a50-a06d-27d82d328c64"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "from azureml.core import Model\r\n",
        " \r\n",
        "\r\n",
        "model = ws.models['projetCloud_model']\r\n",
        "scaler = ws.models['projetCloud_scaler']\r\n",
        "df_columns = ws.models['projetCloud_df_cols']\r\n",
        "\r\n",
        "print(model.name, 'version', model.version)\r\n",
        "\r\n",
        "# Create a folder for the deployment files\r\n",
        "deployment_folder = './service'\r\n",
        "os.makedirs(deployment_folder, exist_ok=True)\r\n",
        "print(deployment_folder, 'folder created.')\r\n",
        "\r\n",
        "# Set path for scoring script\r\n",
        "script_file = 'projetCloud_api.py'\r\n",
        "script_path = os.path.join(deployment_folder,script_file)"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1646792679999
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "953c2cb2-90a0-4a3f-a492-4206f51ee059"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_path\r\n",
        "import json\r\n",
        "import joblib\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "# Called when the service is loaded\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    # Get the path to the deployed model file and load it\r\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'projetCloud_model.pkl')\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "# Called when a request is received\r\n",
        "def run(raw_data):\r\n",
        "    # Get the input data as a numpy array\r\n",
        "    data = np.array(json.loads(raw_data)['data'])\r\n",
        "    # Get a prediction from the model\r\n",
        "    predictions = model.predict(data)\r\n",
        "    # Get the corresponding classname for each prediction (0 or 1)\r\n",
        "    classnames = ['not-diabetic', 'diabetic']\r\n",
        "    predicted_classes = []\r\n",
        "    for prediction in predictions:\r\n",
        "        predicted_classes.append(classnames[prediction])\r\n",
        "    # Return the predictions as JSON\r\n",
        "    return json.dumps(predicted_classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing ./service/projetCloud-api.py\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "a2bc3f74-22d0-417b-bf4a-71bcfda5ad81"
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "\r\n",
        "# Configure the scoring environment\r\n",
        "service_env = Environment(name='service-env')\r\n",
        "python_packages = ['scikit-learn', 'azureml-defaults', 'azure-ml-api-sdk']\r\n",
        "for package in python_packages:\r\n",
        "    service_env.python.conda_dependencies.add_pip_package(package)\r\n",
        "inference_config = InferenceConfig(source_directory=deployment_folder,\r\n",
        "                                   entry_script=script_file,\r\n",
        "                                   environment=service_env)\r\n",
        "\r\n",
        "# Configure the web service container\r\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\r\n",
        "\r\n",
        "# Deploy the model as a service\r\n",
        "print('Deploying model...')\r\n",
        "service_name = \"diabetes-service\"\r\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\r\n",
        "service.wait_for_deployment(True)\r\n",
        "print(service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Error, invalid name \"projetCloud-api\" for provided entry script. The script must be importable as a valid python module, and must adhere to standard module naming. This means it must be a valid python identifier and not a part of the set of python standard keywords.\n\n"
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Error, invalid name \"projetCloud-api\" for provided entry script. The script must be importable as a valid python module, and must adhere to standard module naming. This means it must be a valid python identifier and not a part of the set of python standard keywords.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error, invalid name \\\"projetCloud-api\\\" for provided entry script. The script must be importable as a valid python module, and must adhere to standard module naming. This means it must be a valid python identifier and not a part of the set of python standard keywords.\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m package \u001b[38;5;129;01min\u001b[39;00m python_packages:\n\u001b[1;32m      9\u001b[0m     service_env\u001b[38;5;241m.\u001b[39mpython\u001b[38;5;241m.\u001b[39mconda_dependencies\u001b[38;5;241m.\u001b[39madd_pip_package(package)\n\u001b[0;32m---> 10\u001b[0m inference_config \u001b[38;5;241m=\u001b[39m \u001b[43mInferenceConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mentry_script\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscript_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Configure the web service container\u001b[39;00m\n\u001b[1;32m     15\u001b[0m deployment_config \u001b[38;5;241m=\u001b[39m AciWebservice\u001b[38;5;241m.\u001b[39mdeploy_configuration(cpu_cores\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, memory_gb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/model.py:2124\u001b[0m, in \u001b[0;36mInferenceConfig.__init__\u001b[0;34m(self, entry_script, runtime, conda_file, extra_docker_file_steps, source_directory, enable_gpu, description, base_image, base_image_registry, cuda_version, environment)\u001b[0m\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_image_registry \u001b[38;5;241m=\u001b[39m base_image_registry \u001b[38;5;129;01mor\u001b[39;00m ContainerRegistry()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment \u001b[38;5;241m=\u001b[39m environment\n\u001b[0;32m-> 2124\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/model.py:2240\u001b[0m, in \u001b[0;36mInferenceConfig.validate_configuration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m script_extension \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   2238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WebserviceException(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid driver type. Currently only Python drivers are supported.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   2239\u001b[0m                               logger\u001b[38;5;241m=\u001b[39mmodule_logger)\n\u001b[0;32m-> 2240\u001b[0m \u001b[43mvalidate_entry_script_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruntime \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_RUNTIMES\u001b[38;5;241m.\u001b[39mkeys()):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   2243\u001b[0m     runtimes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_RUNTIMES\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m UNDOCUMENTED_RUNTIMES)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_model_management/_util.py:904\u001b[0m, in \u001b[0;36mvalidate_entry_script_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \n\u001b[1;32m    899\u001b[0m \u001b[38;5;124;03m:param name:\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;124;03m:type name: str\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;124;03m:raises: WebserviceException\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39misidentifier() \u001b[38;5;129;01mor\u001b[39;00m iskeyword(name):\n\u001b[0;32m--> 904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WebserviceException(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError, invalid name \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for provided entry script. The script must be importable \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    905\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mas a valid python module, and must adhere to standard module naming. This means it \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    906\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmust be a valid python identifier and not a part of the set of python standard \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    907\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeywords.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name), logger\u001b[38;5;241m=\u001b[39mmodule_logger)\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error, invalid name \"projetCloud-api\" for provided entry script. The script must be importable as a valid python module, and must adhere to standard module naming. This means it must be a valid python identifier and not a part of the set of python standard keywords.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error, invalid name \\\"projetCloud-api\\\" for provided entry script. The script must be importable as a valid python module, and must adhere to standard module naming. This means it must be a valid python identifier and not a part of the set of python standard keywords.\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "8b7e51fb-b97d-40c7-84cd-821b0bbd02ec"
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}